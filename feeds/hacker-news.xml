<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Hacker News Top Stories</title><link>https://news.ycombinator.com/</link><description>Top stories from Hacker News</description><language>en-us</language><lastBuildDate>Wed, 17 Dec 2025 20:05:10 +0000</lastBuildDate><item><title>alpr.watch</title><link>https://news.ycombinator.com/item?id=46290916</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46290916</guid><pubDate>Tue, 16 Dec 2025 16:54:19 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://alpr.watch/"&gt;alpr.watch&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;For years I&amp;#x27;ve thought about doing an &amp;quot;art project&amp;quot; to make people more aware of the fact they are being observed – but I never actually got up and did it.&lt;p&gt;The idea was to seek spots in the city where public web cams are pointed at, and paint QR codes on the ground at those spots (using a template), linking to the camera stream. So when curious passerbys scan the code, they see themselves in a camera stream and feel &amp;quot;watched&amp;quot;.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 866 | &lt;strong&gt;Author:&lt;/strong&gt; theamk&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46290916"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>866</hn_points><hn_author>theamk</hn_author><hn_order>16</hn_order></item><item><title>No Graphics API</title><link>https://news.ycombinator.com/item?id=46293062</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46293062</guid><pubDate>Tue, 16 Dec 2025 19:20:17 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.sebastianaaltonen.com/blog/no-graphics-api"&gt;www.sebastianaaltonen.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;This is a fantastic article that demonstrates how many parts of vulkan and DX12 are no longer needed.&lt;p&gt;I hope the IHVs have a look at it because current DX12 seems semi abandoned, with it not supporting buffer pointers even when every gpu made on the last 10 (or more!) years can do pointers just fine, and while Vulkan doesnt do a 2.0 release that cleans things, so it carries a lot of baggage, and specially, tons of drivers that dont implement the extensions that really improve things.&lt;p&gt;If this api existed, you could emulate openGL on top of this faster than current opengl to vulkan layers, and something like SDL3 gpu would get a 3x&amp;#x2F;4x boost too.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 776 | &lt;strong&gt;Author:&lt;/strong&gt; ryandrake&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46293062"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>776</hn_points><hn_author>ryandrake</hn_author><hn_order>18</hn_order></item><item><title>Announcing the Beta release of ty</title><link>https://news.ycombinator.com/item?id=46294289</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46294289</guid><pubDate>Tue, 16 Dec 2025 20:52:45 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://astral.sh/blog/ty"&gt;astral.sh&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Hopefully it gets added to this comparison:&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;htmlpreview.github.io&amp;#x2F;?https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;python&amp;#x2F;typing&amp;#x2F;blob&amp;#x2F;main&amp;#x2F;conformance&amp;#x2F;results&amp;#x2F;results.html" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;htmlpreview.github.io&amp;#x2F;?https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;python&amp;#x2F;typ...&lt;/a&gt;&lt;p&gt;If that table is anything to go by, Pyright is not to be underestimated.&lt;p&gt;I have briefly tried ty (LSP) in Emacs and it seems to work well so far. The only questionable thing I&amp;#x27;ve encountered is that when the signature of a method is shown, the type annotations of some parameters seem to be presented in a particularly verbose form compared to what I&amp;#x27;m used to - maybe they&amp;#x27;re technically correct but it can be bit much to look at.&lt;p&gt;Anyway, odds are pretty good that ty is what I will end up using long-term, so thanks and congrats on releasing the first beta!&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 773 | &lt;strong&gt;Author:&lt;/strong&gt; gavide&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46294289"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>773</hn_points><hn_author>gavide</hn_author><hn_order>17</hn_order></item><item><title>AI will make formal verification go mainstream</title><link>https://news.ycombinator.com/item?id=46294574</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46294574</guid><pubDate>Tue, 16 Dec 2025 21:14:49 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html"&gt;martin.kleppmann.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;The funny part of “AI will make formal verification go mainstream” is that it skips over the one step the industry still refuses to do: decide what the software is supposed to do in the first place.&lt;p&gt;We already have a ton of orgs that can’t keep a test suite green or write an honest invariant in a code comment, but somehow we’re going to get them to agree on a precise spec in TLA+&amp;#x2F;Dafny&amp;#x2F;Lean and treat it as a blocking artifact? That’s not an AI problem, that’s a culture and incentives problem.&lt;p&gt;Where AI + “formal stuff” probably does go mainstream is at the boring edges: property-based tests, contracts, refinement types, static analyzers that feel like linters instead of capital‑P “Formal Methods initiatives”. Make it look like another checkbox in CI and devs will adopt it; call it “verification” and half the org immediately files it under “research project we don’t have time for”.&lt;p&gt;Will include this thread in my &lt;a href="https:&amp;#x2F;&amp;#x2F;hackernewsai.com&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;hackernewsai.com&amp;#x2F;&lt;/a&gt; newsletter.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 770 | &lt;strong&gt;Author:&lt;/strong&gt; evankhoury&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46294574"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>770</hn_points><hn_author>evankhoury</hn_author><hn_order>14</hn_order></item><item><title>Pricing Changes for GitHub Actions</title><link>https://news.ycombinator.com/item?id=46291156</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46291156</guid><pubDate>Tue, 16 Dec 2025 17:12:02 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://resources.github.com/actions/2026-pricing-changes-for-github-actions/"&gt;resources.github.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;It is us, developers, who convinced our management to purchase GitHub Enterprise to be our forge. We didn&amp;#x27;t pay any heed to the values of software freedom. A closed source, proprietary software had good features. We saw that and convinced our management to purchase it. Never mind what cost it would impose in the future when the good software gets bad owners. Never mind that there were alternatives that were inferior but were community-developed, community-maintained and libre.&lt;p&gt;The writing is in the wall. First it was UX annoyances. Then it was GitHub Actions woes. Now it is paying money for running their software on your own hardware. It&amp;#x27;s only going to go downhill. Is it a good time now to learn from our mistakes and convince our teams and management to use community-maintained, libre alternatives? They may be inferior. They may lack features. But they&amp;#x27;re not going to pull user hostile tricks like this on you and me. And hey, if they are lacking features, maybe we should convince our management to let us contribute time to the community to add those features? It&amp;#x27;s a much better investment than sinking money into a software that will only grow more and more user hostile, isn&amp;#x27;t it?&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 759 | &lt;strong&gt;Author:&lt;/strong&gt; kevin-david&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46291156"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>759</hn_points><hn_author>kevin-david</hn_author><hn_order>26</hn_order></item><item><title>Is Mozilla trying hard to kill itself?</title><link>https://news.ycombinator.com/item?id=46299934</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46299934</guid><pubDate>Wed, 17 Dec 2025 09:37:24 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://infosec.press/brunomiguel/is-mozilla-trying-hard-to-kill-itself"&gt;infosec.press&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;&amp;gt;&amp;gt; He says he could begin to block ad blockers in Firefox and estimates that’d bring in another $150 million, but he doesn’t want to do that. It feels off-mission.&lt;p&gt;&amp;gt; It may be just me, but I read this as “I don&amp;#x27;t want to   but I&amp;#x27;ll kill AdBlockers in Firefox for buckerinos ”.&lt;p&gt;Yes, that does seem like a pretty uncharitable interpretation of that quote. I read it as &amp;quot;we won&amp;#x27;t do it, even though it would bring in $150M USD&amp;quot;.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 717 | &lt;strong&gt;Author:&lt;/strong&gt; pabs3&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46299934"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>717</hn_points><hn_author>pabs3</hn_author><hn_order>24</hn_order></item><item><title>Thin desires are eating life</title><link>https://news.ycombinator.com/item?id=46283276</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46283276</guid><pubDate>Tue, 16 Dec 2025 00:50:41 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.joanwestenberg.com/thin-desires-are-eating-your-life/"&gt;www.joanwestenberg.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;I really like this article.&lt;p&gt;I bake bread.  I have spent a good deal of time optimizing the recipe for deliciousness but also for time efficiency. Proving in a warm oven is a great tip.  Also baking two loaves at a time!&lt;p&gt;All this nit picking about writing style is disappointing.  I like that this person got their ideas out there.  They are good ideas.  Legible and easy to parse == good enough. I don&amp;#x27;t care about the writing style any more than that and you shouldn&amp;#x27;t either.  It is a waste of everyone&amp;#x27;s time... yours especially.&lt;p&gt;It&amp;#x27;s very nice to hear about someone else who is interested in doing hard things&amp;#x2F;real things. Seems like there ought to be a meet up or a get together opportunity for people working on stuff like that.  Perhaps a get-together where everyone gives a 2-5 minute talk about something they are working on then we all hang out for another hour or two.  Seems like alcohol might help get the wheels spinning?&lt;p&gt;I fully appreciate the need for a catchy headline with a hook (it got me!) but I wonder if these ideas would be more powerful&amp;#x2F;useful if expressed in positive language rather than doom speak?  I guess doom speak is the fashion these days and we all have to conform to the dominant paradigm... at least a little around the edges.&lt;p&gt;Generally... Bravo.  Nice piece.  Nice ideas.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 670 | &lt;strong&gt;Author:&lt;/strong&gt; mitchbob&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46283276"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>670</hn_points><hn_author>mitchbob</hn_author><hn_order>28</hn_order></item><item><title>Mozilla appoints new CEO Anthony Enzor-Demeo</title><link>https://news.ycombinator.com/item?id=46288491</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46288491</guid><pubDate>Tue, 16 Dec 2025 13:53:14 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://blog.mozilla.org/en/mozilla/leadership/mozillas-next-chapter-anthony-enzor-demeo-new-ceo/"&gt;blog.mozilla.org&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Having worked at Mozilla a while ago, the CEO role is one I wouldn&amp;#x27;t wish on my worst enemy. Success is oddly defined: it&amp;#x27;s a non-profit (well, a for-profit owned by a non-profit) that needs to make a big profit in a short amount of time. And anything done to make that profit will annoy the community.&lt;p&gt;I hope Anthony leans into what makes Mozilla special. The past few years, Mozilla&amp;#x27;s business model has been to just meekly &amp;quot;us-too!&amp;quot; trends... IoT, Firefox OS, and more recently AI.&lt;p&gt;What Mozilla is good at, though, is taking complex things the average user doesn&amp;#x27;t really understand, and making it palpable and safe. They did this with web standards... nobody cared about web standards, but Mozilla focused on usability.&lt;p&gt;(Slide aside, it&amp;#x27;s not a coincidence the best CEO Mozilla ever had was a designer.)&lt;p&gt;I&amp;#x27;m not an AI hater, but I don&amp;#x27;t think Mozilla can compete here. There&amp;#x27;s just too much good stuff already, and it&amp;#x27;s not the type of thing Mozilla will shine with.&lt;p&gt;Instead, if I were CEO, I&amp;#x27;d go the opposite way: I&amp;#x27;d focus on privacy. Not AI privacy, but privacy in general. Buy a really great email provider, and start to own &amp;quot;identity on the internet&amp;quot;. As there&amp;#x27;s more bots and less privacy, identity is going to be incredibly important over the years.. and right now, Google defacto owns identity. Make it free, but also give people a way to pay.&lt;p&gt;Would this work? I don&amp;#x27;t know. But like I said, it&amp;#x27;s not a job I envy.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 575 | &lt;strong&gt;Author:&lt;/strong&gt; recvonline&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46288491"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>575</hn_points><hn_author>recvonline</hn_author><hn_order>29</hn_order></item><item><title>GPT Image 1.5</title><link>https://news.ycombinator.com/item?id=46291941</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46291941</guid><pubDate>Tue, 16 Dec 2025 18:07:07 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://openai.com/index/new-chatgpt-images-is-here/"&gt;openai.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;platform.openai.com&amp;#x2F;docs&amp;#x2F;models&amp;#x2F;gpt-image-1.5" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;platform.openai.com&amp;#x2F;docs&amp;#x2F;models&amp;#x2F;gpt-image-1.5&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Okay results are in for GenAI Showdown with the new gpt-image 1.5 model for the editing portions of the site!&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;genai-showdown.specr.net&amp;#x2F;image-editing" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;genai-showdown.specr.net&amp;#x2F;image-editing&lt;/a&gt;&lt;p&gt;Conclusions&lt;p&gt;- OpenAI has always had some of the strongest prompt understanding alongside the weakest image fidelity. This update goes some way towards addressing this weakness.&lt;p&gt;- It&amp;#x27;s leagues better at making localized edits without altering the entire image&amp;#x27;s aesthetic than gpt-image-1, doubling the previous score from 4&amp;#x2F;12 to 8&amp;#x2F;12 and the only model that &lt;i&gt;legitimately passed the Giraffe prompt&lt;/i&gt;.&lt;p&gt;- It&amp;#x27;s one of the most steerable models with a 90% compliance rate&lt;p&gt;Updates to GenAI Showdown&lt;p&gt;- Added outtakes sections to each model&amp;#x27;s detailed report in the Text-to-Image category, showcasing notable failures and unexpected behaviors.&lt;p&gt;- New models have been added including REVE and Flux.2 Dev (a new locally hostable model).&lt;p&gt;- Finally got around to implementing a weighted scoring mechanism which considers pass&amp;#x2F;fail, quality, and compliance for a more holistic model evaluation (click pass&amp;#x2F;fail icon to toggle between scoring methods).&lt;p&gt;If you just want to compare gpt-image-1, gpt-image-1.5, and NB Pro at the same time:&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;genai-showdown.specr.net&amp;#x2F;image-editing?models=o4,nbp,g15" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;genai-showdown.specr.net&amp;#x2F;image-editing?models=o4,nbp...&lt;/a&gt;&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 499 | &lt;strong&gt;Author:&lt;/strong&gt; charlierguo&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46291941"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>499</hn_points><hn_author>charlierguo</hn_author><hn_order>27</hn_order></item><item><title>40 percent of fMRI signals do not correspond to actual brain activity</title><link>https://news.ycombinator.com/item?id=46288415</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46288415</guid><pubDate>Tue, 16 Dec 2025 13:46:57 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity"&gt;www.tum.de&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;My previous job was at a startup doing BMI, for research. For the first time I had the chance to work with expensive neural signal measurement tools (mainly EEG for us, but some teams used fMRI). and quickly did I learn how absolute horrible the signal to noise ratio (SNR) was in this field.&lt;p&gt;And how it was almost impossible to reproduce many published and well cited result. It was both exciting and jarring to talk with the neuroscientist, because they ofc knew about this and knew how to read the papers but the one doing more funding&amp;#x2F;business side ofc didn&amp;#x27;t really spend much time putting emphasis on that.&lt;p&gt;One of the team presented a accepted paper that basically used Deep Learning (Attention) to predict images that a person was thinking of, from the fMRI signals. When I asked &amp;quot;but DL is proven to be able to find pattern even in random noise, so how can you be sure this is not just overfitting to artefact?&amp;quot; and there wasn&amp;#x27;t really any answer to that (or rather the publication didn&amp;#x27;t take that in to account, although that can be experimentally determined). Still, a month later I saw tech explore or some tech news writing an article about it, something like &amp;quot;AI can now read your brain&amp;quot; and the 1984 implications yada yada.&lt;p&gt;So this is indeed something probably most practitioners, masters and PhD, realize relatively early.&lt;p&gt;So now that someone says &amp;quot;you know mindfulness is proven to change your brainwaves?&amp;quot; I always add my story &amp;quot;yes, but the study was done with EEG, so I don&amp;#x27;t trust the scientific backing of it&amp;quot; (but anecdotally, it helps me)&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 481 | &lt;strong&gt;Author:&lt;/strong&gt; geox&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46288415"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>481</hn_points><hn_author>geox</hn_author><hn_order>30</hn_order></item><item><title>No AI* Here – A Response to Mozilla's Next Chapter</title><link>https://news.ycombinator.com/item?id=46295268</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46295268</guid><pubDate>Tue, 16 Dec 2025 22:07:49 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.waterfox.com/blog/no-ai-here-response-to-mozilla/"&gt;www.waterfox.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;&amp;gt; Large language models are something else entirely*. They are black boxes. You cannot audit them. You cannot truly understand what they do with your data. You cannot verify their behaviour. And Mozilla wants to put them at the heart of the browser and that doesn&amp;#x27;t sit well.&lt;p&gt;Am I being overly critical here or is this kind of a silly position to have right after talking about how neural machine translation is okay? Many of Firefox&amp;#x27;s LLM features like summarization afaik are powered by local models (hell even Chrome has local model options). It&amp;#x27;s weird to say neural translation is not a black box but LLMs are somehow black boxes that we cannot hope to understand what they do with the data, especially when viewed a bit fuzzily LLMs are scaled up versions of an architecture that was originally used for neural translation. Neural translation also has unverifiable behavior in the same sense.&lt;p&gt;I could interpret some of the data talk as talking about non local models but this very much seems like a more general criticism of LLMs as a whole when talking about Firefox features. Moreover, some of the critiques like verifiability of outputs and unlimited scope still don&amp;#x27;t make sense in this context. Browser LLM features except for explicitly AI browsers like Comet have so far had some scoping to their behavior, either in very narrow scopes like translation or summarization. The broadest scope I can think of is the side panels that show up which allow you to ask about a web page with context. Even then, I do not see what is inherently problematic about such scoping since the output behavior is confined to the side panel.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 473 | &lt;strong&gt;Author:&lt;/strong&gt; MrAlex94&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46295268"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>473</hn_points><hn_author>MrAlex94</hn_author><hn_order>23</hn_order></item><item><title>Gemini 3 Flash: frontier intelligence built for speed</title><link>https://news.ycombinator.com/item?id=46301851</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46301851</guid><pubDate>Wed, 17 Dec 2025 16:42:13 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://blog.google/products/gemini/gemini-3-flash/"&gt;blog.google&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Don’t let the “flash” name fool you, this is an amazing model.&lt;p&gt;I have been playing with it for the past few weeks, it’s genuinely my new favorite; it’s so fast and it has such a vast world knowledge that it’s more performant than Claude Opus 4.5 or GPT 5.2 extra high, for a fraction (basically order of magnitude less!!) of the inference time and price&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 457 | &lt;strong&gt;Author:&lt;/strong&gt; meetpateltech&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46301851"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>457</hn_points><hn_author>meetpateltech</hn_author></item><item><title>AWS CEO says replacing junior devs with AI is 'one of the dumbest ideas'</title><link>https://news.ycombinator.com/item?id=46302267</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46302267</guid><pubDate>Wed, 17 Dec 2025 17:08:35 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.finalroundai.com/blog/aws-ceo-ai-cannot-replace-junior-developers"&gt;www.finalroundai.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;The thing people miss in these “replace juniors with AI” takes is that juniors were never mainly about cheap hands on keyboards. They’re the only people in the org who are still allowed to ask “dumb” questions without losing face, and those questions are often the only signal you get that your abstractions are nonsense.&lt;p&gt;What AI does is remove a bunch of the humiliating, boring parts of being junior: hunting for the right API by cargo-culting Stack Overflow, grinding through boilerplate, getting stuck for hours on a missing import. If a half-decent model can collapse that search space for them, you get to spend more of their ramp time on “here’s how our system actually fits together” instead of “here’s how for-loops work in our house style”.&lt;p&gt;If you take that setup and then decide “cool, now we don’t need juniors at all”, you’re basically saying you want a company with no memory and no farm system – just an ever-shrinking ring of seniors arguing about strategy while no one actually grows into them.&lt;p&gt;Always love to include a good AI x work thread in my &lt;a href="https:&amp;#x2F;&amp;#x2F;hackernewsai.com&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;hackernewsai.com&amp;#x2F;&lt;/a&gt; newsletter.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 415 | &lt;strong&gt;Author:&lt;/strong&gt; birdculture&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46302267"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>415</hn_points><hn_author>birdculture</hn_author><hn_order>2</hn_order></item><item><title>Tell HN: HN was down</title><link>https://news.ycombinator.com/item?id=46301921</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46301921</guid><pubDate>Wed, 17 Dec 2025 16:48:18 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://news.ycombinator.com/item?id=46301921"&gt;news.ycombinator.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;- HN errored on all authenticated requests with 502 Bad Gateway. It did still respond to a limited amount of unauthenticated requests with presumably cached pages, which did not get updated. The last post on &amp;#x2F;newest claimed &amp;quot;0 minutes ago&amp;quot;, but was actually much older (1:32:57 PM GMT) and not the newest post.&lt;p&gt;- This status page actually identified the outage: &lt;a href="https:&amp;#x2F;&amp;#x2F;hackernews.onlineornot.com&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;hackernews.onlineornot.com&amp;#x2F;&lt;/a&gt; - Pages by Hund and Statuspal did not show the outage.&lt;p&gt;- The last post before the outage was &lt;a href="https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=46301823"&gt;https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=46301823&lt;/a&gt; (1:39:59 PM GMT). The last comment was &lt;a href="https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=46301848"&gt;https:&amp;#x2F;&amp;#x2F;news.ycombinator.com&amp;#x2F;item?id=46301848&lt;/a&gt; (1:41:54 PM GMT).&lt;p&gt;- There was an average of ~4 seconds per comment just prior to the outage. Based on this, HN likely went down at 1:41:58 PM GMT.&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Yes, sorry! We&amp;#x27;re investigating, but my current theory is we got overloaded because I relaxed some of our anti-crawler protections a few days ago.&lt;p&gt;(The reason I did that is that the anti-crawler protections also unfortunately hit some legit users, and we don&amp;#x27;t want to block legit users. However, it seems that I turned the knobs down too far.)&lt;p&gt;In this case, though, we had a secondary failure: PagerDuty woke me up at 5:24am, I checked HN and it seemed fine, so I told PagerDuty the problem was resolved. But the problem wasn&amp;#x27;t resolved - at that point I was just sleeping through it.&lt;p&gt;I&amp;#x27;ll add more as we find out more, but it probably won&amp;#x27;t be till later this afternoon PST.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 318 | &lt;strong&gt;Author:&lt;/strong&gt; uyzstvqs&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46301921"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>318</hn_points><hn_author>uyzstvqs</hn_author><hn_order>5</hn_order></item><item><title>Coursera to combine with Udemy</title><link>https://news.ycombinator.com/item?id=46301346</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46301346</guid><pubDate>Wed, 17 Dec 2025 12:45:40 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://investor.coursera.com/news/news-details/2025/Coursera-to-Combine-with-Udemy-to-Empower-the-Global-Workforce-with-Skills-for-the-AI-Era/default.aspx"&gt;investor.coursera.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;I was a Udemy instructor for ~10 years selling tech courses but focused more on delivering courses through my own site for the last ~5-6 years.&lt;p&gt;Something never felt right with how Udemy promoted courses. I used to have a top selling course there, selling thousands of copies a month and now it gets basically no sales but it&amp;#x27;s still one of the highest rated courses in that niche on their platform. It&amp;#x27;s just no longer ranked or promoted by Udemy, for years.&lt;p&gt;I have no evidence of this but my personal opinion is their ranking is probably not fully automated and they have special offers and deals with certain instructors and if you&amp;#x27;re not a part of this club, oh well.&lt;p&gt;Again, it&amp;#x27;s all speculation but I can only go by what my numbers are. They were small scale life changing and now nothing but the quality of the courses I produced didn&amp;#x27;t change. It doesn&amp;#x27;t make sense. Of course it could be one big coincidence too, but this has been tracked and analyzed over years.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 277 | &lt;strong&gt;Author:&lt;/strong&gt; throwaway019254&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46301346"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>277</hn_points><hn_author>throwaway019254</hn_author><hn_order>4</hn_order></item><item><title>Sega Channel: VGHF Recovers over 100 Sega Channel ROMs (and More)</title><link>https://news.ycombinator.com/item?id=46288024</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46288024</guid><pubDate>Tue, 16 Dec 2025 13:07:14 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://gamehistory.org/segachannel/"&gt;gamehistory.org&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;One of the most interesting things in this release IMO is the internal documents from Sega Channel management. For example, in this binder &lt;a href="https:&amp;#x2F;&amp;#x2F;archive.gamehistory.org&amp;#x2F;item&amp;#x2F;ef6246e4-79be-4b02-b262-af2881fdc16d" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;archive.gamehistory.org&amp;#x2F;item&amp;#x2F;ef6246e4-79be-4b02-b262...&lt;/a&gt; there&amp;#x27;s a bunch of research documents trying to figure out how to turn the service around after it began underperforming their expectations.&lt;p&gt;It seems like the main problem they ran into was that the service appealed mainly to the small minority of &amp;quot;heavy players&amp;quot; (who they defined as playing more than 14 hours per week). Their original projections were that they could target cable subscribers who own Genesis systems and play games more than 4 hours a week, but they found that most people who weren&amp;#x27;t gaming fanatics preferred to own a few games and rent games as needed rather than subscribe to Sega Channel.&lt;p&gt;The other big problem they ran into was parental resistance. A large amount of parents they talked to viewed Sega Channel as an &amp;quot;open tap&amp;quot; that would increase their child&amp;#x27;s time spent playing games. An ongoing subscription also was only a one-time &amp;quot;give&amp;quot; from the parent to the child, whereas buying&amp;#x2F;renting games was one &amp;quot;give&amp;quot; per occasion, which was more psychologically attractive to the parents.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 274 | &lt;strong&gt;Author:&lt;/strong&gt; wicket&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46288024"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>274</hn_points><hn_author>wicket</hn_author><hn_order>36</hn_order></item><item><title>Purrtran – ᓚᘏᗢ – A Programming Language for Cat People</title><link>https://news.ycombinator.com/item?id=46256504</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46256504</guid><pubDate>Sat, 13 Dec 2025 18:02:46 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://github.com/cmontella/purrtran"&gt;github.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;&amp;gt; PURRTRAN allocates all variables to an arena called the &amp;quot;Litterbox&amp;quot;. The Litterbox must be manually emptied at least once a day by the user, or Hex&amp;#x27;s cleanliness and love will decrease. The Litterbox can overflow, which will cause Hex to become very displeased and may lead to unexpected program behavior, as Hex will begin storing variables in your source code text buffer instead of the Litterbox until it&amp;#x27;s cleaned.&lt;p&gt;I&amp;#x27;m cackling like a madman, thank you for this op.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 257 | &lt;strong&gt;Author:&lt;/strong&gt; simonpure&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46256504"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>257</hn_points><hn_author>simonpure</hn_author><hn_order>55</hn_order></item><item><title>Japan to revise romanization rules for first time in 70 years</title><link>https://news.ycombinator.com/item?id=46286292</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46286292</guid><pubDate>Tue, 16 Dec 2025 08:54:58 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.japantimes.co.jp/news/2025/08/21/japan/panel-hepburn-style-romanization/"&gt;www.japantimes.co.jp&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;Curiously enough, Hepburn romanization fixes some ambiguities in Japanese (Japanese written in kana alone) while introducing others.&lt;p&gt;The ō in Hepburn could correspond to おう or おお or オー. That&amp;#x27;s an ambiguity.&lt;p&gt;Where does Hepburn disambiguate?&lt;p&gt;In Japanese, an E column kana followed by I sometimes makes a long E, like in 先生 (sen + sei -&amp;gt; sensē). The &amp;quot;SEI&amp;quot; is one unit.  But in other situations it does not, like in a compound word ending in the E kana, where the second word starts with I. For instance 酒色 (sake + iro -&amp;gt; sakeiro, not sakēro).&lt;p&gt;Hepburn distinguishes these; the hiragana spelling does not!&lt;p&gt;This is one of the issues that makes it very hard to read Japanese that is written with hiragana only, rather than kanji.   No word breaks and not knowing whether せい is supposed to be sē or sei.&lt;p&gt;There are curiosities like karaage which is &amp;quot;kara&amp;quot; (crust) + &amp;quot;age&amp;quot; (fried thing). A lot of the time it is pronounced as karāge, because of the way RA and A come together. Other times you hear a kind of flutter in it which articulates two A&amp;#x27;s.&lt;p&gt;I have no idea which romanization to use. Flip a coin?&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 252 | &lt;strong&gt;Author:&lt;/strong&gt; rgovostes&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46286292"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>252</hn_points><hn_author>rgovostes</hn_author><hn_order>34</hn_order></item><item><title>Bonsai: A Voxel Engine, from scratch</title><link>https://news.ycombinator.com/item?id=46285319</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46285319</guid><pubDate>Tue, 16 Dec 2025 06:06:43 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://github.com/scallyw4g/bonsai"&gt;github.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;It&amp;#x27;s really not that hard to ray trace the voxels instead of using rasterization and allows for way higher voxel counts.&lt;p&gt;&lt;a href="https:&amp;#x2F;&amp;#x2F;dubiousconst282.github.io&amp;#x2F;2024&amp;#x2F;10&amp;#x2F;03&amp;#x2F;voxel-ray-tracing&amp;#x2F;" rel="nofollow"&gt;https:&amp;#x2F;&amp;#x2F;dubiousconst282.github.io&amp;#x2F;2024&amp;#x2F;10&amp;#x2F;03&amp;#x2F;voxel-ray-traci...&lt;/a&gt;&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 243 | &lt;strong&gt;Author:&lt;/strong&gt; jesse__&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46285319"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>243</hn_points><hn_author>jesse__</hn_author><hn_order>59</hn_order></item><item><title>Nvidia Nemotron 3 Family of Models</title><link>https://news.ycombinator.com/item?id=46275111</link><guid isPermaLink="true">https://news.ycombinator.com/item?id=46275111</guid><pubDate>Mon, 15 Dec 2025 14:39:49 +0000</pubDate><description>&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://research.nvidia.com/labs/nemotron/Nemotron-3/"&gt;research.nvidia.com&lt;/a&gt;&lt;/p&gt;
                    &lt;hr/&gt;
                    &lt;div&gt;&lt;b&gt;Top Comment:&lt;/b&gt;&lt;/div&gt;
                    &lt;blockquote style="margin:1.5em 0; padding:1em 1.5em; border-left:4px solid; font-style:italic;"&gt;
                    &lt;p&gt;I don’t do ‘evals’, but I do process billions of tokens every month, and I’ve found these small Nvidia models to be the best by far for their size currently.&lt;p&gt;As someone else mentioned, the GPT-OSS models are also quite good (though I haven’t found how to make them &lt;i&gt;great&lt;/i&gt; yet, though I think they might age well like the Llama 3 models did and get better with time!).&lt;p&gt;But for a defined task, I’ve found task compliance, understanding, and tool call success rates to be some of the highest on these Nvidia models.&lt;p&gt;For example, I have a continuous job that evaluates if the data for a startup company on aVenture.vc could have overlapping&amp;#x2F;conflated two similar but unrelated companies for news articles, research details, investment rounds, etc… which is a token hungry ETL task! And I recently retested this workflow on the top 15 or so models today with &amp;lt;125b parameters, and the Nvidia models were among the best performing for this type of work, particularly around non-hallucination if given adequate grounding.&lt;p&gt;Also, re: cost - I run local inference on several machines that run continuously, in addition to routing through OpenRouter and the frontier providers, and was pleasantly surprised to find that if I’m a paying customer of OpenRouter otherwise, the free variant there from Nvidia is quite generous for limits, too.&lt;/p&gt;
                    &lt;/blockquote&gt;
                    &lt;p&gt;&lt;strong&gt;Points:&lt;/strong&gt; 240 | &lt;strong&gt;Author:&lt;/strong&gt; ewt-nv&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=46275111"&gt;View All Comments&lt;/a&gt;&lt;/p&gt;</description><hn_points>240</hn_points><hn_author>ewt-nv</hn_author><hn_order>40</hn_order></item></channel></rss>